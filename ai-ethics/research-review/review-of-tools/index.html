<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>From What to How | In That Number</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="From What to How" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices" />
<meta property="og:description" content="From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices" />
<link rel="canonical" href="http://localhost:4000/ai-ethics/research-review/review-of-tools/" />
<meta property="og:url" content="http://localhost:4000/ai-ethics/research-review/review-of-tools/" />
<meta property="og:site_name" content="In That Number" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-27T19:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="From What to How" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"From What to How","dateModified":"2020-12-27T19:00:00-05:00","datePublished":"2020-12-27T19:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/ai-ethics/research-review/review-of-tools/"},"url":"http://localhost:4000/ai-ethics/research-review/review-of-tools/","description":"From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/dark.css">
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,700,700i|Lora:400,400i,700,700i">
  <link rel="alternate" type="application/atom+xml" title="In That Number" href="/atom.xml">
<!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  from-what-to-how">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    
  <div class="navigation-wrapper">
    <a href="#menu-toggle" id="menu-toggle">Menu</a>
    <nav id="primary-nav" class="site-nav animated drop">
      <ul><li><a href="/">Home</a></li><li><a href="/posts/">Posts</a></li><li><a href="/about/">About</a></li><li><a href="https://docs.google.com/document/d/e/2PACX-1vQTjAwbmRfpbJZgljWxkHGEsKDsl1YtBo7Oc335Z-YiE1dWgRA0Pf6vxS29n-M917fkm0aKD2f5F5PD/pub">CV</a></li><li><a href="/search/">Search</a></li></ul>
    </nav>
  </div><!-- /.navigation-wrapper -->


    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">In That Number</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">A blog about data science practice, ethics, and the things in between.</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <header class="page-header">
        
        
          <h1 id="page-title" class="page-title p-name">From What to How
</h1>
        
      </header>

      <div class="page-sidebar">
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2020-12-27T19:00:00-05:00"><a class="u-url" href="">December 27, 2020</a>
</time>

  </div>
</div>

        
  <h3 class="page-taxonomies-title">Categories</h3>
  
  <ul class="page-taxonomies"><li class="page-taxonomy"><a class="p-category" href="/categories/#ai-ethics" title="Pages filed under ai-ethics">ai-ethics</a></li><li class="page-taxonomy"><a class="p-category" href="/categories/#research-review" title="Pages filed under research-review">research-review</a></li>
  </ul>


        

      </div>

      <div class="page-content">
        <div class="e-content">
          <h1 id="from-what-to-how-an-initial-review-of-publicly-available-ai-ethics-tools-methods-and-research-to-translate-principles-into-practices">From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices</h1>

<p><strong>A 2019 review of AI ethics tools and methods</strong></p>

<p>Publisher: Morley, J., Floridi, L., Kinsey, L. et al. From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices. Sci Eng Ethics 26, 2141–2168 (2020). https://doi.org/10.1007/s11948-019-00165-5</p>

<h2 id="summary">Summary</h2>
<p>The authors begin by asserting that code, and particularly code that facilitates machine learning, is both our greatest threat and our greatest promise. Citing a review of AI ethics principles, the argues note that ethically-aligned machine learning is typically defined as having the following properties: beneficence, non-maleficence, autonomy, justice, and explainability. This consensus on the definition of AI creates a foundation upon which technologists can “communicate expectations and evaluate deliverables”. However, very few of these guidelines set technical expectations. The authors note that the next step in defining ethical machine learning guidelines is to translate the <strong>what</strong> outlined in the principles to <strong>how</strong>.</p>

<p>To bridge this gap, the authors define a typology that maps the foundational principles above to each stage of the machine learning algorithm design process. They identified 425 papers which ostensibly answer the question of “how to develop an ethical algorithmic system”. The typology developed is intended to show machine learning developers what ethical ML tools are already available. The authors find that not all principles have tools for each stage of the algorithm design process. Explainability, which is more easily implemented than the other principles, is overrepresented in the toolset. Unlike beneficence, non-maleficence, autonomy, and justice, explainability is not a moral principle, so tools that enable transparency like LIME and SHAP are insufficient alone. Instead of ensuring explainability at the back end, the authors propose that transparency is prioritized at the beginning of the design process.</p>

<p>The authors also note that few of the tools provide ways to assess the impact of an ML algorithm on an individual in a dataset. The <em>deployment</em> column of the typology is blank, highlighting the need for “pro- ethically designed human-computer interaction (at an individual level) or networks of ML systems (at a group level)”. The authors assert that not enough research has been done in the field of translating predictions to decisions in the context of algorithmic systems. Finally, the tools in the typology are generally not usable, as they are either not easily applicable in practice or too complex for a wide set of users, as in the case of open source code libraries.</p>

<p>ML researchers from all disciplines will need to accept that: (1) AI is built on assumptions; (2) human behaviour is complex; (3) algorithms can have unfair consequences; (4) algorithmic predictions can be hard to interpret (Vaughan &amp; Wallach, 2016); (5) trade-offs are usually inevitable; and (6) positive, ethical features are open to progressive increase. Ethical principles should not be applied once or not, but should be regularly re-applied or applied differently, depending on changing needs throughout the ML development process.</p>

<h2 id="my-takeaways">My Takeaways</h2>

<p>I don’t think this article provided me with anything I didn’t already know. Through my (albeit limited) review of AI ethics principles, it’s evident that a wide gap exists between framework and technical practice. The guidelines I tend to see fall on one of two extremes: high-level principles that outline the values algorithmic systems should embed, or low-level technical implementations of those values (such as transparency as in SHAP, or fairness as in fairlearn) without explicating a context for prioritizing those results within organizational and/or project goals. I appreciated that the authors’ literature review and typology reflected this sentiment, and that they provided a thorough synthesis of the existing ML ethics conversation.</p>

<p>I think one of my most important takeaways is at the end of the article, where the authors describe what topics the ML research community prioritize. They put the most important topic at the bottom of the list: <strong>the evaluation and creation of pro-ethical business models and incentive structures that balance the costs and rewards of investing in ethical AI across society</strong>. I firmly believe that none of the other topics can be on the table, not a commitment to reproducibility and openness, not evaluation of currently implemented tools, not the development of a common language, etc. until ML developers have organizational buy-in. Organizational buy-in only occurs when ethical priorities align with financial priorities, and in some cases the only way to facilitate that alignment may be a fundamental restructuring of financial priorities.</p>

<p>The authors note that they eventually hope to create a searchable database with AI ethics tools and methods, and I think that would be particularly helpful to practitioners. The authors note an urgent need to progress research in the AI for Social Good field, and having a comprehensive database of tools (with a common/standardized language to discuss concepts) would be a good first step to making that research feasible.</p>

<h2 id="notable-quotes">Notable Quotes</h2>

<h2 id="citations">Citations</h2>


        </div>

        
          <div class="page-share">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Freview-of-tools%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--facebook btn--small"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i> <span>Share</span></a>
  <a href="https://twitter.com/intent/tweet?text=From+What+to+How%20http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Freview-of-tools%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--twitter btn--small"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> <span>Tweet</span></a>
  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Freview-of-tools%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--linkedin btn--small"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> <span>LinkedIn</span></a>
  <a href="https://reddit.com/submit?title=From+What+to+How&url=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Freview-of-tools%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--reddit btn--small"><i class="fab fa-fw fa-reddit" aria-hidden="true"></i> <span>Reddit</span></a>
</div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/ai-ethics/research-review/lessons-from-archives/">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Lessons from Archives

      </span>
    </a>
  

  
    <a class="page-next" href="/ai-ethics/research-review/mitigating-dataset-harms/">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Mitigating Dataset Harms Requires Stewardship
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>


    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://github.com/alliesaizan"><i class="fab fa-github-alt fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/alexandra-saizan/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      <p>&copy; 2021 In That Number. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/mmistakes/so-simple-theme" rel="nofollow">So Simple</a>.</p>
    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


  </body>

</html>
