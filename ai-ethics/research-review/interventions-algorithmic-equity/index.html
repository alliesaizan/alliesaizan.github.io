<!DOCTYPE html>
<!--
    So Simple Jekyll Theme 3.2.0
    Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
    Free for personal and commercial use under the MIT license
    https://github.com/mmistakes/so-simple-theme/blob/master/LICENSE
-->
<html lang="en-US" class="no-js">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  

  
    
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Interventions for Algorithmic Equity | In That Number</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Interventions for Algorithmic Equity" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Toward Situated Interventions for Algorithmic Equity: Lessons from the Field" />
<meta property="og:description" content="Toward Situated Interventions for Algorithmic Equity: Lessons from the Field" />
<link rel="canonical" href="http://localhost:4000/ai-ethics/research-review/interventions-algorithmic-equity/" />
<meta property="og:url" content="http://localhost:4000/ai-ethics/research-review/interventions-algorithmic-equity/" />
<meta property="og:site_name" content="In That Number" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-26T19:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Interventions for Algorithmic Equity" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"Interventions for Algorithmic Equity","dateModified":"2020-11-26T19:00:00-05:00","datePublished":"2020-11-26T19:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/ai-ethics/research-review/interventions-algorithmic-equity/"},"url":"http://localhost:4000/ai-ethics/research-review/interventions-algorithmic-equity/","description":"Toward Situated Interventions for Algorithmic Equity: Lessons from the Field","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  

  <script>
    /* Cut the mustard */
    if ( 'querySelector' in document && 'addEventListener' in window ) {
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + 'js';
    }
  </script>

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/skins/dark.css">
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,700,700i|Lora:400,400i,700,700i">
  <link rel="alternate" type="application/atom+xml" title="In That Number" href="/atom.xml">
<!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

</head>


  <body class="layout--post  interventions-for-algorithmic-equity">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#primary-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    
  <div class="navigation-wrapper">
    <a href="#menu-toggle" id="menu-toggle">Menu</a>
    <nav id="primary-nav" class="site-nav animated drop">
      <ul><li><a href="/">Home</a></li><li><a href="/posts/">Posts</a></li><li><a href="/about/">About</a></li><li><a href="https://docs.google.com/document/d/e/2PACX-1vQTjAwbmRfpbJZgljWxkHGEsKDsl1YtBo7Oc335Z-YiE1dWgRA0Pf6vxS29n-M917fkm0aKD2f5F5PD/pub">CV</a></li><li><a href="/search/">Search</a></li></ul>
    </nav>
  </div><!-- /.navigation-wrapper -->


    <header class="masthead">
  <div class="wrap">
    
    
    
      
        <div class="site-title animated fadeIn"><a href="/">In That Number</a></div>
      
      <p class="site-description animated fadeIn" itemprop="description">A blog about data science practice, ethics, and the things in between.</p>
    
  </div>
</header><!-- /.masthead -->


    <main id="main" class="main-content" aria-label="Content">
  <article class="h-entry">
    

    <div class="page-wrapper">
      <header class="page-header">
        
        
          <h1 id="page-title" class="page-title p-name">Interventions for Algorithmic Equity
</h1>
        
      </header>

      <div class="page-sidebar">
        <div class="page-author h-card p-author"><div class="author-info">
    <time class="page-date dt-published" datetime="2020-11-26T19:00:00-05:00"><a class="u-url" href="">November 26, 2020</a>
</time>

  </div>
</div>

        
  <h3 class="page-taxonomies-title">Categories</h3>
  
  <ul class="page-taxonomies"><li class="page-taxonomy"><a class="p-category" href="/categories/#ai-ethics" title="Pages filed under ai-ethics">ai-ethics</a></li><li class="page-taxonomy"><a class="p-category" href="/categories/#research-review" title="Pages filed under research-review">research-review</a></li>
  </ul>


        

      </div>

      <div class="page-content">
        <div class="e-content">
          <h1 id="toward-situated-interventions-for-algorithmic-equity-lessons-from-the-field">Toward Situated Interventions for Algorithmic Equity: Lessons from the Field</h1>

<p><strong>Technical interventions to reduce algorithmic bias are incomplete without community-based interventions that focus on the socio-political context of technical systems.</strong></p>

<p>Publisher: Katell, M. et al. Toward Situated Interventions for Algorithmic Equity: Lessons from the Field. FAT ‘20, January 27–30, 2020, Barcelona, Spain.</p>

<h2 id="summary">Summary</h2>

<p>I haven’t read much on non-technical means of assuring algorithmic fairness, so on first blush I think this will be an interesting contribution to the field. This work is intended to fill the gap in algorithmic bias research surrounding social-context-based means of reducing harms from algorithmic systems. The authors use the framework of situated knowledge to study technical systems. Situated knowledge refers to the “product of embodied vantage points, located historically.”<sup>1</sup> The authors also incorporate elements of the human-computer interaction field to contextualize their participatory discourse, and draw on their experiences
developing the <a href="https://www.aclu-wa.org/AEKit">Algorithmic Equity Toolkit</a>. The authors document their development of the Algorithmic Equity Toolkit as a response to the lack of safeguards against algorithmic bias in the 2017 Seattle Surveillance Ordinance. Participatory design methods such as contextual inquiry were used to center affected populations in the development of the toolkit. Throughout the process, the authors partnered with community-based civil rights organizations and data science institutes for their input. The toolkit, which was designed to assess the impact of particular technologies in public settings, has three tenets: (1) Determine whether a system is AI, (2) Ask tough questions, (3) Better learn how ML works and when it fails. Stakeholder-provided input facilitated continuous integration / continuous development creation  of the toolkit. Among other takeaways, the authors found that non-technical measures can meaningfully impact
algorithmic accountability. Stakeholders don’t need to have a technical background to assess outcome(s) of and identify alternatives to technical systems. The authors conclude that future automated decision system interventions should consider the framework of situated context.</p>

<h2 id="my-takeaways">My Takeaways</h2>

<p>The authors believe that participatory methods that center those most disparately affected by algorithmic systems should be integrated in the practice of data science. And I agree, I think it’s crucial for data scientists to recognize that the tools they build, even seemingly divorced from any social context, can prop up social inequities. On the toolkit itself, tenets (2) and (3) seem duplicative, and tenet (3) might be better listed as “understand how <strong>this particular</strong> ML system works.” Another important takeaway is that it’s not enough to identify the risks associated with automated decision systems. Even if the system works as intended without any disparate impacts, it may still produce undesirable results (e.g., facial recognition surveillance systems).</p>

<p>Overall, this research provides a blueprint for the “interpretative data scientist”, that is, a data scientist who is deeply ingrained with community organizations, is attuned to the needs of vulnerable populations and the potentially negative impacts of the technical systems being developed, and is an expert communicator of not just technical topics, but also understanding how those topics are situated within a socio-political context. I am hopeful that these skills increasingly become part of data science training.</p>

<h2 id="notable-quotes">Notable Quotes</h2>

<ol>
  <li>“A more inclusive data science practice will result in novel conventions of work which attend to fairness, accountability, transparency, and equity as an explicit part of research method and practice– rather than as topic alone.”</li>
  <li>“…such efforts emphasize the importance of equitable processes determinative of equitable outcomes.”</li>
  <li>“…the most meaningful measures towards fairness, accountability, and transparency are not necessarily technical but are instead informed through contextualized understanding about how a given tool or technology is implemented and contested in practice.”</li>
</ol>

<h2 id="citations">Citations</h2>

<ol>
  <li>Donna Haraway. 1988. Situated knowledges: The science question in feminism and the privilege of partial perspective. <em>Feminist studies</em> 14, 3 (1988), 575–599.</li>
</ol>

        </div>

        
          <div class="page-share">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Finterventions-algorithmic-equity%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--facebook btn--small"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i> <span>Share</span></a>
  <a href="https://twitter.com/intent/tweet?text=Interventions+for+Algorithmic+Equity%20http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Finterventions-algorithmic-equity%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--twitter btn--small"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> <span>Tweet</span></a>
  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Finterventions-algorithmic-equity%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--linkedin btn--small"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> <span>LinkedIn</span></a>
  <a href="https://reddit.com/submit?title=Interventions+for+Algorithmic+Equity&url=http%3A%2F%2Flocalhost%3A4000%2Fai-ethics%2Fresearch-review%2Finterventions-algorithmic-equity%2F" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="btn btn--reddit btn--small"><i class="fab fa-fw fa-reddit" aria-hidden="true"></i> <span>Reddit</span></a>
</div>

        

        

        <nav class="page-pagination" role="navigation">
  
    <a class="page-previous" href="/intro/welcome/">
      <h4 class="page-pagination-label">Previous</h4>
      <span class="page-pagination-title">
        <i class="fas fa-arrow-left"></i> Getting Started

      </span>
    </a>
  

  
    <a class="page-next" href="/ai-ethics/research-review/lessons-from-archives/">
      <h4 class="page-pagination-label">Next</h4>
      <span class="page-pagination-title">
        Lessons from Archives
 <i class="fas fa-arrow-right"></i>
      </span>
    </a>
  
</nav>

      </div>
    </div>
  </article>
</main>


    <footer id="footer" class="site-footer">
  <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
<div class="social-icons"><a class="social-icon" href="https://github.com/alliesaizan"><i class="fab fa-github-alt fa-2x" title="GitHub"></i></a><a class="social-icon" href="https://www.linkedin.com/in/alexandra-saizan/"><i class="fab fa-linkedin fa-2x" title="LinkedIn"></i></a></div><div class="copyright">
    
      <p>&copy; 2021 In That Number. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/mmistakes/so-simple-theme" rel="nofollow">So Simple</a>.</p>
    
  </div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>


  </body>

</html>
